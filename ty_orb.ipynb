{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "def detect_orb_keypoints(image_path):\n",
    "    \"\"\"\n",
    "    使用ORB检测器提取图像的特征点。\n",
    "    \n",
    "    参数:\n",
    "    - image_path: 图像文件路径\n",
    "    \n",
    "    返回:\n",
    "    - keypoints: 关键点列表\n",
    "    - descriptors: 描述符列表\n",
    "    \"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=500)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    kp, des = orb.detectAndCompute(img, None)\n",
    "    return kp, des\n",
    "\n",
    "def match_descriptors(des1, des2):\n",
    "    \"\"\"\n",
    "    使用BFMatcher匹配描述符。\n",
    "    \n",
    "    参数:\n",
    "    - des1, des2: 描述符列表\n",
    "    \n",
    "    返回:\n",
    "    - matches: 匹配结果\n",
    "    \"\"\"\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    return matches\n",
    "\n",
    "def print_matches(matches):\n",
    "    # 设置每行的字符宽度和每列的匹配数目\n",
    "    width = 120  # 每行的字符宽度\n",
    "    matches_per_row = 10  # 每列的匹配数目\n",
    "\n",
    "    # 打印匹配的距离，以矩阵形式显示\n",
    "    print(\"Matches:\")\n",
    "    # 计算需要打印的行数和行号的宽度\n",
    "    rows = (len(matches) - 1) // matches_per_row + 1\n",
    "    row_numbers = list(range(1, rows + 1))\n",
    "    line_width = len(str(len(matches) // matches_per_row + 1))  # 行号的最大位数\n",
    "\n",
    "    # 确定距离数值的格式化字符串，确保等宽显示\n",
    "    max_distance = max(matches, key=lambda x: x.distance).distance\n",
    "    distance_width = len(f\"{max_distance:.4f}\")  # 距离数值的最大位数\n",
    "\n",
    "    # 计算每行的格式化字符串\n",
    "    formatted_rows = []\n",
    "    for i in range(rows):\n",
    "        # 计算当前行的起始和结束索引\n",
    "        start_index = i * matches_per_row\n",
    "        end_index = start_index + matches_per_row\n",
    "        # 获取当前行的匹配项\n",
    "        row_matches = matches[start_index:end_index]\n",
    "        # 创建一个格式化的字符串列表，每个匹配项后面都有足够的空格\n",
    "        formatted_distances = [f\"{match.distance:>{distance_width}.2f}\" for match in row_matches]\n",
    "        # 构建行号格式化字符串\n",
    "        line_number = f\"[{str(i + 1).zfill(line_width)}]\"\n",
    "        # 将行号和匹配距离连接成一个字符串，并添加到列表中\n",
    "        formatted_rows.append(f\"{line_number} {' '.join(formatted_distances)}\")\n",
    "\n",
    "    # 打印每行格式化后的字符串\n",
    "    for row in formatted_rows:\n",
    "        print(row.ljust(width))\n",
    "\n",
    "    # 如果需要，也可以将这些信息保存到日志文件中\n",
    "    log_file_path = 'matches_log.txt'\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        log_file.write(\"Matches (first N shown):\\n\")\n",
    "        for row in formatted_rows:\n",
    "            log_file.write(f\"{row}\\n\")\n",
    "\n",
    "def compare_images_by_orb_features(image1_path, image2_path, log_detail=False):\n",
    "    \"\"\"\n",
    "    比较两张图像的ORB特征，判断是否相似，并增加详细日志输出辅助问题判断。\n",
    "    修正逻辑：若总匹配数达到原图特征点数的90%，则视作相似。\n",
    "    \"\"\"\n",
    "\n",
    "    if log_detail: print(f\"Comparing images by ORB features\\nimg1: {image1_path}\\nimg2: {image2_path}\")\n",
    "    match_details = {}\n",
    "    \n",
    "    kp1, des1 = detect_orb_keypoints(image1_path)\n",
    "    kp2, des2 = detect_orb_keypoints(image2_path)\n",
    "    \n",
    "    # 新增日志：检测到的关键点数量\n",
    "    match_details[\"keypoints_image1\"] = len(kp1)\n",
    "    match_details[\"keypoints_image2\"] = len(kp2)\n",
    "    if log_detail: print(f\"KeyPoints Count: img1 -> {match_details['keypoints_image1']}, img2 -> {match_details['keypoints_image2']}\")\n",
    "\n",
    "    # 检查是否成功检测到特征点\n",
    "    if des1 is None or des2 is None:\n",
    "        if log_detail: print(f\"No keypoints detected\")\n",
    "        match_details[\"status\"] = \"No keypoints\"\n",
    "        return False, match_details\n",
    "    \n",
    "    matches = match_descriptors(des1, des2)\n",
    "        \n",
    "    # 输出匹配数量\n",
    "    match_details[\"total_matches\"] = len(matches)\n",
    "    if log_detail: print(f\"Total matches between img1 and img2: {match_details['total_matches']}\")\n",
    "    \n",
    "    if len(matches) == 0:  \n",
    "        if log_detail: print(f\"No matches found between img1 and img2\")\n",
    "        match_details[\"status\"] = \"No matches\"\n",
    "        return False, match_details\n",
    "\n",
    "    # 对匹配进行排序，以便最小的距离排在前面\n",
    "    matches = sorted(matches, key=lambda m: m.distance)\n",
    "    if log_detail: print_matches(matches)\n",
    "\n",
    "    # # 定义比率测试的阈值\n",
    "    # ratio_threshold = 1.5\n",
    "\n",
    "    # # 使用比率测试过滤好的匹配\n",
    "    # good_matches = []\n",
    "    # for i, match in enumerate(matches):\n",
    "    #     # 如果是第一个匹配点，跳过（因为没有前一个匹配点进行比较）\n",
    "    #     if i == 0:\n",
    "    #         continue\n",
    "        \n",
    "    #     # 计算当前匹配与前一个匹配的距离比率\n",
    "    #     ratio = match.distance / matches[i - 1].distance\n",
    "        \n",
    "    #     # 如果比率小于阈值，则认为当前匹配是一个好的匹配\n",
    "    #     if ratio < ratio_threshold:\n",
    "    #         good_matches.append(match)\n",
    "\n",
    "    # 找到最佳匹配距离\n",
    "    best_match_distance = matches[0].distance\n",
    "    if log_detail: print(f\"Best Match Distance: {best_match_distance}\")\n",
    "    \n",
    "    threshold = 150\n",
    "    ratio_threshold = 1.5\n",
    "\n",
    "    good_matches = [m for m in matches if m.distance <= best_match_distance * ratio_threshold]\n",
    "    \n",
    "    # 输出好匹配的数量和最佳匹配距离\n",
    "    match_details[\"good_matches\"] = len(good_matches)\n",
    "    match_details[\"best_match_distance\"] = best_match_distance\n",
    "    if log_detail: print(f\"Good matches count: {match_details['good_matches']} with best match distance: {match_details['best_match_distance']}\")\n",
    "\n",
    "    if len(good_matches) > threshold:\n",
    "        if log_detail: print(f\"img1 and img2 are similar.\")\n",
    "        match_details[\"status\"] = \"Similar\"\n",
    "        return True, match_details\n",
    "    else:\n",
    "        if log_detail: print(f\"img1 and img2 are different.\")\n",
    "        match_details[\"status\"] = \"Different\"\n",
    "        return False, match_details\n",
    "\n",
    "def remove_duplicates_by_orb(directory, remove_from_disk=False):\n",
    "    \"\"\"\n",
    "    使用ORB特征去除目录中的重复图像，并记录详细日志。\n",
    "    \n",
    "    参数:\n",
    "    - directory: 图像文件目录\n",
    "    - remove_from_disk: 是否删除重复文件\n",
    "    \n",
    "    返回:\n",
    "    - unique_images: 唯一图像文件路径列表\n",
    "    \"\"\"\n",
    "    directory_path = Path(directory)\n",
    "    total_files = sum(1 for item in directory_path.iterdir() if item.is_file())\n",
    "    print(f\"开始处理图像去重，总文件数：{total_files}\")\n",
    "\n",
    "    log_file_path = os.path.join(os.getcwd(), f\"log_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.txt\")\n",
    "    with open(log_file_path, \"w\") as f:\n",
    "        f.write(\"开始处理图像去重...\\n\")\n",
    "\n",
    "    unique_images = []\n",
    "    duplicates = defaultdict(list)  # 使用字典存储重复图片组\n",
    "    for img_path in tqdm(directory_path.glob(\"*\"), total=total_files, desc='Processing'):\n",
    "        if not img_path.suffix.lower() in (\".jpg\", \".png\"):\n",
    "            continue\n",
    "\n",
    "        is_duplicate = False\n",
    "        for unique_path in unique_images:\n",
    "            if compare_images_by_orb_features(str(img_path), str(unique_path))[0]:\n",
    "                duplicates[str(unique_path)].append(img_path)\n",
    "                is_duplicate = True\n",
    "                break\n",
    "                \n",
    "        if not is_duplicate:\n",
    "            unique_images.append(img_path)\n",
    "\n",
    "    # 记录去重结果并打印日志\n",
    "    group_count = 1\n",
    "    with open(log_file_path, \"a\") as f:\n",
    "        for unique_path, dup_group in duplicates.items():\n",
    "            log_message = f\"第 {group_count} 组重复图片，共 {len(dup_group) + 1} 张\\n\"\n",
    "            print(log_message[:-1])  # 打印日志内容到控制台，去除末尾换行符\n",
    "            f.write(log_message)\n",
    "            \n",
    "            w, h = get_image_dimensions(unique_path)\n",
    "            log_message = f\"{unique_path} w:{w} h:{h} - 保留（尺寸最大）\\n\"\n",
    "            print(log_message[:-1])\n",
    "            f.write(log_message)\n",
    "            \n",
    "            for duplicate in dup_group:\n",
    "                w, h = get_image_dimensions(duplicate)\n",
    "                log_message = f\"{duplicate} w:{w} h:{h} - 标记删除\\n\"\n",
    "                print(log_message[:-1])\n",
    "                f.write(log_message)\n",
    "            group_count += 1\n",
    "            \n",
    "        f.write(f\"总重复组数：{group_count - 1}\\n\")\n",
    "        print(f\"总重复组数：{group_count - 1}\")\n",
    "\n",
    "    print(f\"去重后数量: {len(unique_images)}, 总重复文件数: {sum(len(v) for v in duplicates.values())}\")\n",
    "    print(f\"详细信息见 {log_file_path}\")\n",
    "\n",
    "    # 根据需求移除重复文件\n",
    "    if remove_from_disk:\n",
    "        for duplicates_list in duplicates.values():\n",
    "            for duplicate in duplicates_list:\n",
    "                try:\n",
    "                    os.remove(str(duplicate))\n",
    "                    print(f\"已删除重复文件: {duplicate}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"删除文件 {duplicate} 出错: {e}\")\n",
    "\n",
    "    return unique_images\n",
    "\n",
    "def get_image_dimensions(image_path):\n",
    "    \"\"\"获取图像的宽度和高度\"\"\"\n",
    "    img = cv2.imread(str(image_path))  \n",
    "    height, width, _ = img.shape\n",
    "    return width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing images by ORB features\n",
      "img1: F:\\pic\\test\\45dfc99djw1fa2zr8vfvsj22sj3q7kjt.jpg\n",
      "img2: F:\\pic\\test\\45dfc99djw1fa2zrgfwtlj22sj3q7x6w.jpg\n",
      "KeyPoints Count: img1 -> 500, img2 -> 500\n",
      "Total matches between img1 and img2: 141\n",
      "Best Match Distance: 9.0\n",
      "Matches:\n",
      "[01]    9.00   13.00   15.00   15.00   16.00   17.00   17.00   18.00   19.00   19.00                                    \n",
      "[02]   19.00   19.00   20.00   20.00   20.00   21.00   21.00   22.00   22.00   22.00                                    \n",
      "[03]   22.00   22.00   22.00   22.00   22.00   22.00   23.00   24.00   24.00   24.00                                    \n",
      "[04]   24.00   24.00   24.00   24.00   25.00   25.00   26.00   27.00   27.00   27.00                                    \n",
      "[05]   27.00   28.00   28.00   28.00   28.00   29.00   29.00   29.00   29.00   29.00                                    \n",
      "[06]   29.00   30.00   32.00   33.00   33.00   33.00   33.00   33.00   34.00   34.00                                    \n",
      "[07]   34.00   35.00   35.00   37.00   37.00   37.00   37.00   38.00   38.00   38.00                                    \n",
      "[08]   39.00   39.00   40.00   40.00   40.00   41.00   42.00   42.00   43.00   45.00                                    \n",
      "[09]   45.00   45.00   46.00   47.00   47.00   47.00   47.00   48.00   49.00   49.00                                    \n",
      "[10]   50.00   50.00   50.00   51.00   51.00   51.00   52.00   52.00   52.00   53.00                                    \n",
      "[11]   54.00   54.00   56.00   56.00   57.00   57.00   58.00   58.00   58.00   59.00                                    \n",
      "[12]   59.00   59.00   59.00   60.00   61.00   61.00   62.00   62.00   64.00   64.00                                    \n",
      "[13]   65.00   65.00   66.00   66.00   67.00   68.00   68.00   71.00   72.00   72.00                                    \n",
      "[14]   73.00   73.00   73.00   74.00   75.00   75.00   77.00   79.00   80.00   82.00                                    \n",
      "[15]   83.00                                                                                                            \n",
      "Good matches count: 2 with best match distance: 9.0\n",
      "img1 and img2 are different.\n"
     ]
    }
   ],
   "source": [
    "detail_info = compare_images_by_orb_features(\n",
    "    \"F:\\\\pic\\\\test\\\\45dfc99djw1fa2zr8vfvsj22sj3q7kjt.jpg\",\n",
    "    \"F:\\\\pic\\\\test\\\\45dfc99djw1fa2zrgfwtlj22sj3q7x6w.jpg\",\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用函数并接收返回的去重后文件列表\n",
    "# unique_images_list = remove_duplicates_by_orb(\"F:\\\\pic\\\\test\", False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
