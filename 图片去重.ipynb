{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mProcessed with HashDetector[4776618784], similar_groups count: 1\u001b[0m\n",
      "Detecting duplicates using perceptual hash, precision: 8\n",
      "images cnt: 86\n",
      "Found 51 unique hashes\n",
      "Found 29 unique images, 22 similar groups\n",
      "Saving description to /Users/chenweichu/dev/data/test/descriptor_HashDetector_20240508194321.txt\n",
      "\u001b[33munique count: 29\u001b[0m\n",
      "\u001b[33mProcessed with ORBDetector[4776619792], similar_groups count: 23\u001b[0m\n",
      "Saving description to /Users/chenweichu/dev/data/test/descriptor_ORBDetector_20240508194335.txt\n",
      "\u001b[33munique count: 31\u001b[0m\n",
      "Final unique images count: 31\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from imagehash import phash\n",
    "from itertools import combinations\n",
    "from typing import List, Set, Tuple\n",
    "from termcolor import colored\n",
    "import datetime\n",
    "\n",
    "class ImageDescriptor:\n",
    "    def __init__(self, unique_images: Set[Path], similar_groups: List[List[Path]]):\n",
    "        self.unique_images = unique_images\n",
    "        self.similar_groups = similar_groups\n",
    "\n",
    "    def serialize(self, filepath: str):\n",
    "        \"\"\"将描述信息保存为文本文件\"\"\"\n",
    "        print(f\"Saving description to {filepath}\")\n",
    "        with open(filepath, 'w') as file:\n",
    "            file.write(\"Unique Images:\\n\")\n",
    "            for image in self.unique_images:\n",
    "                file.write(f\"{image.name}\\n\")\n",
    "            file.write(\"\\nSimilar Groups:\\n\")\n",
    "            for group in self.similar_groups:\n",
    "                file.write(f\"Group:\\n\")\n",
    "                for image in group:\n",
    "                    file.write(f\"{image.name}\\n\")\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "class HashDetector:\n",
    "    def __init__(self, precision: int):\n",
    "        self.precision = precision\n",
    "\n",
    "    def detect(self, images: List[Path]) -> ImageDescriptor:\n",
    "        print(f\"Detecting duplicates using perceptual hash, precision: {self.precision}\\nimages cnt: {len(images)}\")\n",
    "        hash_dict = {}\n",
    "        for image_path in images:\n",
    "            with Image.open(image_path) as img:\n",
    "                img_hash = phash(img.convert(\"L\").resize((self.precision, self.precision)))\n",
    "                if img_hash in hash_dict:\n",
    "                    hash_dict[img_hash].append(image_path)\n",
    "                else:\n",
    "                    hash_dict[img_hash] = [image_path]\n",
    "        print(f\"Found {len(hash_dict)} unique hashes\")\n",
    "        unique_images = set()\n",
    "        similar_groups = []\n",
    "        for paths in hash_dict.values():\n",
    "            if len(paths) == 1:\n",
    "                unique_images.add(paths[0])\n",
    "            else:\n",
    "                similar_groups.append(paths)\n",
    "        print(f\"Found {len(unique_images)} unique images, {len(similar_groups)} similar groups\")\n",
    "        return ImageDescriptor(unique_images, similar_groups)\n",
    "\n",
    "class ORBDetector:\n",
    "    def __init__(self, nfeatures: int, threshold: float):\n",
    "        self.nfeatures = nfeatures\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def detect(self, images: List[Path]) -> ImageDescriptor:\n",
    "        keypoints_dict = {img: self._extract_features(img) for img in images}\n",
    "        similar_groups = []\n",
    "        unique_images = set(images)\n",
    "        \n",
    "        for img1, img2 in combinations(images, 2):\n",
    "            kp1, des1 = keypoints_dict[img1]\n",
    "            kp2, des2 = keypoints_dict[img2]\n",
    "            if des1 is not None and des2 is not None:\n",
    "                if self._match_features(des1, des2) > self.nfeatures * self.threshold:\n",
    "                    similar_groups.append([img1, img2])\n",
    "                    unique_images.discard(img1)\n",
    "                    unique_images.discard(img2)\n",
    "\n",
    "        return ImageDescriptor(unique_images, similar_groups)\n",
    "\n",
    "    def _extract_features(self, image_path: Path):\n",
    "        orb = cv2.ORB_create(self.nfeatures)\n",
    "        img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "        return orb.detectAndCompute(img, None)\n",
    "\n",
    "    def _match_features(self, des1, des2):\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(des1, des2)\n",
    "        return len(matches)\n",
    "\n",
    "class ImageDeduplicator:\n",
    "    def __init__(self, directory: str):\n",
    "        self.directory = directory\n",
    "        self.detectors = [\n",
    "            HashDetector(8),\n",
    "            ORBDetector(500, 0.7)\n",
    "        ]\n",
    "\n",
    "    def deduplicate(self):\n",
    "        images = [path for path in Path(self.directory).glob(\"*\") if path.suffix.lower() in [\".jpg\", \".png\"]]\n",
    "        descriptor = ImageDescriptor(set(), [images])\n",
    "\n",
    "        for detector in self.detectors:\n",
    "            print(colored(f\"Processed with {type(detector).__name__}[{id(detector)}], similar_groups count: {len(descriptor.similar_groups)}\", \"yellow\"))\n",
    "            result = detector.detect(images)\n",
    "            descriptor.unique_images.update(result.unique_images)\n",
    "            descriptor.similar_groups.extend(result.similar_groups)\n",
    "\n",
    "            # 序列化当前描述对象\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            filepath = f\"{self.directory}/descriptor_{type(detector).__name__}_{timestamp}.txt\"\n",
    "            descriptor.serialize(filepath)\n",
    "\n",
    "            print(colored(f\"unique count: {len(descriptor.unique_images)}\", \"yellow\"))\n",
    "        \n",
    "        return descriptor\n",
    "\n",
    "# Example usage\n",
    "deduplicator = ImageDeduplicator(\"/Users/chenweichu/dev/data/test\")\n",
    "final_descriptor = deduplicator.deduplicate()\n",
    "print(f\"Final unique images count: {len(final_descriptor.unique_images)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-img-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
