{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from imagehash import phash\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def process_images(directory, log_file_path, sample_precision):\n",
    "    \"\"\"\n",
    "    处理图像文件，计算哈希值并筛选出唯一的图像文件路径列表。\n",
    "\n",
    "    参数：\n",
    "        directory (str): 包含图像文件的目录路径。\n",
    "        log_file_path (str): 日志文件的路径。\n",
    "        sample_precision (int): 图片采样精度，即图片缩放尺寸。\n",
    "\n",
    "    返回：\n",
    "        tuple: 哈希字典、唯一图像文件路径列表和处理失败的文件列表。\n",
    "    \"\"\"\n",
    "    # 初始化变量\n",
    "    hashes = {}\n",
    "    unique_images = []\n",
    "    failed_files = []\n",
    "    \n",
    "    # 获取目录中的所有文件列表\n",
    "    directory_path = Path(directory)\n",
    "    total_files = sum(1 for item in directory_path.iterdir() if item.is_file())\n",
    "\n",
    "    # 记录日志：开始处理图像文件\n",
    "    print(\"开始计算哈希，总文件数：{}\".format(total_files))\n",
    "    log2file(log_file_path, \"总文件数：{}\".format(total_files))\n",
    "    files = directory_path.glob(\"*\")\n",
    "\n",
    "    # 遍历目录中的文件\n",
    "    for file_path in tqdm(files, total=total_files, desc='Processing'):\n",
    "        # 判断文件类型，仅处理jpg和png文件\n",
    "        if not file_path.suffix.lower() in (\".jpg\", \".png\"):\n",
    "            continue\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                img_bytes = np.fromfile(f, dtype=np.uint8)\n",
    "                img = cv2.imdecode(img_bytes, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "            if img is None:\n",
    "                err_info = \"警告: 无法读取图像 {}, 跳过.\".format(file_path)\n",
    "                print(err_info)\n",
    "                failed_files.append(err_info)\n",
    "                continue\n",
    "            \n",
    "            img_pil = Image.open(file_path)\n",
    "            img_size = img_pil.size\n",
    "            \n",
    "            img_pil_gray = Image.fromarray(img)\n",
    "            img_hash = phash(img_pil_gray.resize((sample_precision, sample_precision)))\n",
    "            \n",
    "            if img_hash not in hashes:\n",
    "                hashes[img_hash] = {\"paths\": [], \"sizes\": []}\n",
    "            hashes[img_hash][\"paths\"].append(file_path)\n",
    "            hashes[img_hash][\"sizes\"].append(img_size)\n",
    "            \n",
    "            unique_images.append(file_path)\n",
    "        except Exception as e:\n",
    "            # 记录处理失败的文件及错误信息\n",
    "            err_info = \"错误: 处理 {} 时出错: {}\".format(file_path, e)\n",
    "            print(err_info)\n",
    "            failed_files.append(err_info)\n",
    "        \n",
    "    # 返回哈希字典、唯一图像文件路径列表和处理失败的文件列表\n",
    "    return hashes, unique_images, failed_files\n",
    "\n",
    "\n",
    "def remove_duplicate_images(directory, remove_from_disk=False, sample_precision=8):\n",
    "    \"\"\"\n",
    "    删除重复的图像文件。\n",
    "\n",
    "    参数：\n",
    "        directory (str): 包含图像文件的目录路径。\n",
    "        remove_from_disk (bool): 是否从磁盘中删除重复文件，默认为 False。\n",
    "        sample_precision (int): 图片采样精度，即图片缩放尺寸。\n",
    "\n",
    "    返回：\n",
    "        list: 唯一图像文件路径列表。\n",
    "    \"\"\"\n",
    "    # 获取当前工作目录\n",
    "    current_dir = os.getcwd()\n",
    "    # 定义日志文件路径\n",
    "    log_file_path = os.path.join(current_dir, \"log_{}.txt\".format(datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")))\n",
    "\n",
    "    info = \"开始处理图片去重，目录：{directory}，是否删除重复文件：{remove_from_disk}\".format(directory=directory, remove_from_disk=remove_from_disk)\n",
    "    print(info)\n",
    "    log2file(log_file_path, info)\n",
    "\n",
    "    # 检查目录是否存在\n",
    "    if not os.path.isdir(directory):\n",
    "        err_info = \"错误: 目录 {} 不存在。\".format(directory)\n",
    "        print(err_info)\n",
    "        if log_file_path:  # 确保log_file_path已被定义\n",
    "            log2file(log_file_path, err_info)\n",
    "        return []\n",
    "\n",
    "    # 获取目录中的文件列表\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # 检查目录是否为空或没有图片文件\n",
    "    if not files or all(not f.lower().endswith(('.jpg', '.png')) for f in files):\n",
    "        err_info = \"警告: 目录 {} 是空的或不包含任何图片文件。\".format(directory)\n",
    "        print(err_info)\n",
    "        if log_file_path:\n",
    "            log2file(log_file_path, err_info)\n",
    "        return []\n",
    "\n",
    "    # 调用处理图像文件的函数，并传递采样精度参数\n",
    "    hashes, unique_images, failed_files = process_images(directory, log_file_path, sample_precision)\n",
    "    error_files = []  # 用于记录删除重复文件时出现的错误的文件\n",
    "    \n",
    "    # 初始化重复组计数器\n",
    "    duplicate_group_count = 0\n",
    "    \n",
    "    # 遍历哈希字典\n",
    "    for hash_value, data in hashes.items():\n",
    "        # 如果有重复的图像\n",
    "        if len(data[\"paths\"]) > 1:  \n",
    "            duplicate_group_count += 1\n",
    "            info =\"第 {} 组重复图片，共 {} 张，哈希值: {}\".format(duplicate_group_count, len(data['paths']), hash_value)\n",
    "            print(info)\n",
    "            log2file(log_file_path, info)\n",
    "            \n",
    "            # 找到尺寸最大的图像文件\n",
    "            max_size_index = data[\"sizes\"].index(max(data[\"sizes\"], key=lambda x: x[0]*x[1]))\n",
    "            largest_img_path, largest_img_size = data[\"paths\"][max_size_index], data[\"sizes\"][max_size_index]\n",
    "            info = \"{} w:{} h:{} - 保留（尺寸最大）\".format(largest_img_path, largest_img_size[0], largest_img_size[1])\n",
    "            print(info)\n",
    "            log2file(log_file_path, info)\n",
    "            \n",
    "            # 遍历除尺寸最大的图像文件外的其他文件\n",
    "            for idx, (path, size) in enumerate(zip(data[\"paths\"], data[\"sizes\"]), start=1):\n",
    "                if idx != max_size_index + 1:\n",
    "                    info = \"{} w:{} h:{} - 标记删除\".format(path, size[0], size[1])\n",
    "                    print(info)\n",
    "                    log2file(log_file_path, info)\n",
    "                    unique_images.remove(path)\n",
    "                    if not remove_from_disk: continue\n",
    "                    try:\n",
    "                        os.remove(path)\n",
    "                    except Exception as e:\n",
    "                        # 记录删除文件时出现的错误\n",
    "                        err_info = \"错误: 删除文件 {} 时出错: {}\".format(path, e)\n",
    "                        print(err_info)\n",
    "                        error_files.append(err_info)\n",
    "\n",
    "    info = \"总重复组数：{}\".format(duplicate_group_count)\n",
    "    print(info)\n",
    "    log2file(log_file_path, info)\n",
    "\n",
    "    info = \"去重后数量: {}\".format(len(unique_images))\n",
    "    print(info)\n",
    "    log2file(log_file_path, info)\n",
    "    \n",
    "    # 如果存在处理失败或删除文件错误，记录到日志文件中\n",
    "    if failed_files or error_files:\n",
    "        print(\"\\n总共失败或异常文件数:\", len(failed_files) + len(error_files))\n",
    "        for error_info in failed_files + error_files:\n",
    "            print(error_info)\n",
    "            log2file(log_file_path, error_info)\n",
    "    else:\n",
    "        print(\"\\n所有文件均已成功处理，无任何失败或异常情况。\")\n",
    "    print(\"详细信息见 {}\".format(log_file_path))\n",
    "    \n",
    "    # 返回唯一图像文件路径列表\n",
    "    return unique_images\n",
    "\n",
    "\n",
    "def log2file(log_file_path, message):\n",
    "    \"\"\"\n",
    "    记录消息到日志文件。\n",
    "\n",
    "    参数：\n",
    "        log_file_path (str): 日志文件的路径。\n",
    "        message (str): 要记录的消息。\n",
    "    \"\"\"\n",
    "    # 如果文件不存在，就创建一个新文件\n",
    "    if not os.path.exists(log_file_path):\n",
    "        with open(log_file_path, \"w\"):\n",
    "            pass\n",
    "    # 追加写入错误信息到文件\n",
    "    with open(log_file_path, \"a\") as f:\n",
    "        f.write(message + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理图片去重，目录：F:\\pic\\zhytest，是否删除重复文件：False\n",
      "开始计算哈希，总文件数：52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e864465cb1d4592a66f93bf3cf30d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 组重复图片，共 2 张，哈希值: e52192968c4d9bbb\n",
      "F:\\pic\\zhytest\\e0951f8ccda0475c90ec647f63168330_th.jpg w:1242 h:1880 - 保留（尺寸最大）\n",
      "F:\\pic\\zhytest\\e0951f8ccda0475c90ec647f63168330_thcopy.jpg w:1242 h:1880 - 标记删除\n",
      "第 2 组重复图片，共 3 张，哈希值: f939f023467eb049\n",
      "F:\\pic\\zhytest\\551433992CB7682A291A666534355A22.jpg w:2445 h:3264 - 保留（尺寸最大）\n",
      "F:\\pic\\zhytest\\551433992CB7682A291A666534355A22copy2.jpg w:2445 h:3264 - 标记删除\n",
      "F:\\pic\\zhytest\\551433992CB7682A291A666534355A22copy.jpg w:2445 h:3264 - 标记删除\n",
      "总重复组数：2\n",
      "去重后数量: 49\n",
      "\n",
      "所有文件均已成功处理，无任何失败或异常情况。\n",
      "详细信息见 e:\\dev\\face_image_preprocessing\\log_20240505193453.txt\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并接收返回的去重后文件列表\n",
    "unique_images_list = remove_duplicate_images(\"F:\\\\pic\\\\zhytest\", False, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
